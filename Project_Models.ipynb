{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73239cc0-a389-4822-8a87-11fb07345f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries for Images \n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Libraries for Evaluations and Train/Test Split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Model Libraries\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "#VGG16\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#ResNET\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Statistical Test\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Model Visualization\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "#Others\n",
    "from tqdm import tqdm  # Optional: tqdm for progress bar\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8474ce-1c78-41b6-a284-e53b4475cbfa",
   "metadata": {},
   "source": [
    "## CNN2 - max pooling, relu, batch normalization, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb513c3-f53c-4ccd-a265-96bd9a270ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn2.compile(optimizer=tf.keras.optimizers.legacy.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model_cnn2.summary()\n",
    "\n",
    "    # Define a callback to save the best model during training\n",
    "checkpoint = ModelCheckpoint(\"best_model_cnn2.h5\", monitor='val_loss', save_best_only=True)\n",
    "    # Define a callback to save the best model during training in the native Keras format\n",
    "#checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model_cnn2.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust the number of epochs based on your needs\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc36ea2-22dc-4ffc-b36b-049c5cf6031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Keras version: 3.0.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e51f5-2be1-4c56-a90f-bcb22c5d5b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3678c2b-5ba4-4347-afe3-1c9aa787fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(original_model, train_generator, n_splits=5, epochs=5):\n",
    "    dataset_size = train_generator.n\n",
    "    num_classes = len(train_generator.class_indices)\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_performance = []\n",
    "\n",
    "    for train_indices, val_indices in kf.split(range(dataset_size)):\n",
    "        # Creating train and validation sub-generators for each fold\n",
    "        train_subgen = create_subgenerator(train_generator, train_indices)\n",
    "        val_subgen = create_subgenerator(train_generator, val_indices)\n",
    "\n",
    "        # Cloning the original model structure\n",
    "        model = clone_model(original_model)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(train_subgen, epochs=epochs, validation_data=val_subgen, steps_per_epoch=len(train_indices)//train_generator.batch_size, validation_steps=len(val_indices)//train_generator.batch_size)\n",
    "\n",
    "        # Evaluate the model\n",
    "        scores = model.evaluate(val_subgen, verbose=0, steps=len(val_indices)//train_generator.batch_size)\n",
    "        fold_performance.append(scores[1])  # Assuming [1] is accuracy\n",
    "\n",
    "    # Average performance\n",
    "    average_performance = np.mean(fold_performance)\n",
    "    return fold_performance, average_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afe63f-c624-47d7-9cf4-4977082159b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8ffcfb5-38d1-402e-a7b0-89586ecd0842",
   "metadata": {},
   "source": [
    "## CNN3 - max pooling, stride 1,2 , padding = valid, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f24bf-0d40-4595-b2d2-59336feb2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "#num_classes = len(train_generator.class_indices)\n",
    "\n",
    "model_cnn3 = tf.keras.models.Sequential([\n",
    "    Conv2D(32 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2,2) , strides = 2 , padding = 'valid'),\n",
    "\n",
    "    Conv2D(64 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'),\n",
    "    MaxPooling2D((2,2) , strides = 2 , padding = 'valid'),\n",
    "    \n",
    "    Conv2D(64 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'),\n",
    "    MaxPooling2D((2,2) , strides = 2 , padding = 'valid'),\n",
    "    \n",
    "    Conv2D(128 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'),\n",
    "    MaxPooling2D((2,2) , strides = 2 , padding = 'valid'),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(units = 128 , activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units = num_classes, activation='softmax')  # Adjust 'num_classes' based on your task\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Compile the model with the legacy Adam optimizer\n",
    "model_cnn3.compile(optimizer=tf.keras.optimizers.legacy.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Display the model summary\n",
    "model_cnn3.summary()\n",
    "\n",
    "    # Define a callback to save the best model during training\n",
    "checkpoint = ModelCheckpoint(\"best_model_cnn3.h5\", monitor='val_loss', save_best_only=True)\n",
    "    # Define a callback to save the best model during training in the native Keras format\n",
    "#checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model_cnn3.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # Adjust the number of epochs based on your needs\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514bbf2-4c00-41f7-a3cd-d95ebc4eaa86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023565c-9544-48ec-9460-0354eecebce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(original_model, train_generator, n_splits=5, epochs=5):\n",
    "    # Extracting data and labels from the generator\n",
    "    dataset_size = train_generator.n\n",
    "    num_classes = len(train_generator.class_indices)\n",
    "    batch_size = train_generator.batch_size\n",
    "    target_size = train_generator.target_size\n",
    "\n",
    "    X = np.zeros((dataset_size, target_size[0], target_size[1], 3), dtype=np.float32)\n",
    "    y = np.zeros((dataset_size, num_classes), dtype=np.float32)\n",
    "\n",
    "    for i in range(len(train_generator)):\n",
    "        batch_x, batch_y = train_generator.next()\n",
    "        X[i * batch_size:(i + 1) * batch_size] = batch_x\n",
    "        y[i * batch_size:(i + 1) * batch_size] = batch_y\n",
    "\n",
    "    # K-Fold Cross-Validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_performance = []\n",
    "\n",
    "    for train_indices, val_indices in kf.split(X):\n",
    "        # Splitting data\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        # Cloning the original model structure\n",
    "        model = clone_model(original_model)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Training the model\n",
    "        model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
    "\n",
    "        # Evaluating the model\n",
    "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_performance.append(scores[1])  # Assuming [1] is accuracy\n",
    "\n",
    "    # Average performance\n",
    "    average_performance = np.mean(fold_performance)\n",
    "    return fold_performance, average_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
